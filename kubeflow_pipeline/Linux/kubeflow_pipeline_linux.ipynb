{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML: Create production-ready ML pipelines\n",
    "\n",
    "Our goal here is to help you to get the first practical experience with our tool and give you a brief overview on some basic functionalities of ZenML. We will start local in the jupyter notebook but will transition over to a more robust environment with Kubeflow pipelines.\n",
    "\n",
    "This guide is designed to provide a practical introduction to transitioning from local setup to a more production MLOps stack. If you want more detail, our [full documentation](https://docs.zenml.io/) provides more on the concepts and how to implement them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![zenml](assets/zenml.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "b413e26c-e610-4803-e39b-55906cb1f31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\n",
      "Requirement already satisfied: zenml==0.13.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (0.13.1)\n",
      "Requirement already satisfied: sqlmodel<0.1.0,>=0.0.6 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (0.0.8)\n",
      "Requirement already satisfied: distro<2.0.0,>=1.6.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (1.7.0)\n",
      "Requirement already satisfied: rich[jupyter]<13.0.0,>=12.0.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (12.5.1)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.18 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (3.1.27)\n",
      "Requirement already satisfied: apache-beam<3.0.0,>=2.30.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (2.41.0)\n",
      "Requirement already satisfied: ml-pipelines-sdk==1.8.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (1.8.0)\n",
      "Requirement already satisfied: analytics-python<2.0.0,>=1.4.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (1.4.0)\n",
      "Requirement already satisfied: httplib2<0.20,>=0.19.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (0.19.1)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.9.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (1.9.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.0.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (8.1.3)\n",
      "Requirement already satisfied: markupsafe==1.1.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (1.1.1)\n",
      "Requirement already satisfied: pyyaml<6.0.0,>=5.4.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (5.4.1)\n",
      "Requirement already satisfied: nbconvert==6.4.4 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (6.4.4)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.1.5 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (2.8.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (2.4.7)\n",
      "Requirement already satisfied: click-params<0.4.0,>=0.3.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from zenml==0.13.1) (0.3.0)\n",
      "Requirement already satisfied: packaging<21,>=20 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-pipelines-sdk==1.8.0->zenml==0.13.1) (20.9)\n",
      "Requirement already satisfied: portpicker<2,>=1.3.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-pipelines-sdk==1.8.0->zenml==0.13.1) (1.5.2)\n",
      "Requirement already satisfied: jinja2<4,>=2.7.3 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-pipelines-sdk==1.8.0->zenml==0.13.1) (2.11.3)\n",
      "Requirement already satisfied: docker<5,>=4.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-pipelines-sdk==1.8.0->zenml==0.13.1) (4.4.4)\n",
      "Requirement already satisfied: google-apitools<1,>=0.5 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-pipelines-sdk==1.8.0->zenml==0.13.1) (0.5.32)\n",
      "Requirement already satisfied: ml-metadata<1.9.0,>=1.8.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-pipelines-sdk==1.8.0->zenml==0.13.1) (1.8.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.8 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-pipelines-sdk==1.8.0->zenml==0.13.1) (1.12.11)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-pipelines-sdk==1.8.0->zenml==0.13.1) (0.11.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.13 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-pipelines-sdk==1.8.0->zenml==0.13.1) (3.20.1)\n",
      "Requirement already satisfied: bleach in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (5.0.1)\n",
      "Requirement already satisfied: traitlets>=5.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (5.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (4.11.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (0.2.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (0.4)\n",
      "Requirement already satisfied: nbformat>=4.4 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (5.4.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (0.8.4)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (2.12.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (0.5.13)\n",
      "Requirement already satisfied: jupyter-core in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (4.10.0)\n",
      "Requirement already satisfied: testpath in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbconvert==6.4.4->zenml==0.13.1) (0.7.1)\n",
      "Requirement already satisfied: backoff==1.10.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from analytics-python<2.0.0,>=1.4.0->zenml==0.13.1) (1.10.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from analytics-python<2.0.0,>=1.4.0->zenml==0.13.1) (2.28.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from analytics-python<2.0.0,>=1.4.0->zenml==0.13.1) (1.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from analytics-python<2.0.0,>=1.4.0->zenml==0.13.1) (1.16.0)\n",
      "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (3.10.0.2)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (1.7)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (1.4.2)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (3.12.3)\n",
      "Requirement already satisfied: pytz>=2018.3 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (2022.2.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.1.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (2.1.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.33.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (1.47.0)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (2.7.0)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (1.6.0)\n",
      "Requirement already satisfied: orjson<4.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (3.8.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (1.22.1)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (0.3.1.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.14.3 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from click<9.0.0,>=8.0.1->zenml==0.13.1) (4.12.0)\n",
      "Requirement already satisfied: validators<0.19,>=0.18 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from click-params<0.4.0,>=0.3.0->zenml==0.13.1) (0.18.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from gitpython<4.0.0,>=3.1.18->zenml==0.13.1) (4.0.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting typing-extensions>=3.7.0\n",
      "  Using cached typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.9.1)\n",
      "Requirement already satisfied: ipywidgets<8.0.0,>=7.5.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (7.7.1)\n",
      "Requirement already satisfied: SQLAlchemy<=1.4.41,>=1.4.17 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from sqlmodel<0.1.0,>=0.0.6->zenml==0.13.1) (1.4.40)\n",
      "Requirement already satisfied: sqlalchemy2-stubs in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from sqlmodel<0.1.0,>=0.0.6->zenml==0.13.1) (0.0.2a27)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from docker<5,>=4.1->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (1.4.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.18->zenml==0.13.1) (5.0.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (0.1.0)\n",
      "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (2.10.0)\n",
      "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (1.35.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (3.0.1)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-apitools<1,>=0.5->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (4.1.3)\n",
      "Requirement already satisfied: fasteners>=0.14 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-apitools<1,>=0.5->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (0.17.3)\n",
      "Requirement already satisfied: docopt in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<3.0.0,>=2.30.0->zenml==0.13.1) (0.6.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (3.6.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (6.15.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (7.34.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (1.1.1)\n",
      "Requirement already satisfied: attrs<21,>=20.3 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ml-metadata<1.9.0,>=1.8.0->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (20.3.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert==6.4.4->zenml==0.13.1) (7.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert==6.4.4->zenml==0.13.1) (1.5.5)\n",
      "Requirement already satisfied: fastjsonschema in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert==6.4.4->zenml==0.13.1) (2.15.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert==6.4.4->zenml==0.13.1) (3.2.0)\n",
      "Requirement already satisfied: psutil in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from portpicker<2,>=1.3.1->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (5.9.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml==0.13.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml==0.13.1) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml==0.13.1) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml==0.13.1) (2022.6.15)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from SQLAlchemy<=1.4.41,>=1.4.17->sqlmodel<0.1.0,>=0.0.6->zenml==0.13.1) (1.1.3)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from validators<0.19,>=0.18->click-params<0.4.0,>=0.3.0->zenml==0.13.1) (5.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from beautifulsoup4->nbconvert==6.4.4->zenml==0.13.1) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from bleach->nbconvert==6.4.4->zenml==0.13.1) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from importlib-metadata->click<9.0.0,>=8.0.1->zenml==0.13.1) (3.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (1.56.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-auth<3dev,>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (0.2.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-auth<3dev,>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (41.2.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-auth<3dev,>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from google-auth<3dev,>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (4.8)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (1.6.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.1.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (23.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pexpect>4.3 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (3.0.30)\n",
      "Requirement already satisfied: backcall in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert==6.4.4->zenml==0.13.1) (0.18.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->ml-pipelines-sdk==1.8.0->zenml==0.13.1) (0.4.8)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (6.4.12)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.8.3)\n",
      "Requirement already satisfied: prometheus-client in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.14.1)\n",
      "Requirement already satisfied: argon2-cffi in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.15.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (0.2.5)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenml==0.13.1) (2.21)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.8.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
      "kfp 1.8.9 requires typing-extensions<4,>=3.7.4; python_version < \"3.9\", but you have typing-extensions 4.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typing-extensions-4.3.0\n"
     ]
    }
   ],
   "source": [
    "# Install the ZenML CLI tool and Tensorflow\n",
    "!python --version\n",
    "!pip install zenml==0.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages (22.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m⠏\u001b[0m Installing integrations.....\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!zenml integration install kubeflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m⠙\u001b[0m Installing integrations.....\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!zenml integration install tensorflow -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create your first ZenML repository for your project. As ZenML repositories are built on top of Git repositories, you can create yours in a desired empty directory through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "fea5770a-d7de-4169-893c-eae2aa97f517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Initializing ZenML repository at /home/laiml/Desktop/kubeflow_pipeline.\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Initializing ZenML repository at /home/laiml/Desktop/kubeflow_pipeline.\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Initializing ZenML repository at /home/laiml/Desktop/kubeflow_pipeline.\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Initializing ZenML repository at /home/laiml/Desktop/kubeflow_pipeline.\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mZenML repository initialized at \u001b[0m\u001b[2;35m/home/laiml/Desktop/\u001b[0m\u001b[2;95mkubeflow_pipeline.\u001b[0m\n",
      "\u001b[2;32m⠴\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;36mInitializing ZenML repository at /home/laiml/Desktop/kubeflow_pipeline.\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Initializing ZenML repository at /home/laiml/Desktop/kubeflow_pipeline.\n",
      "\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mThe local active profile was initialized to \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m and the local active stack\u001b[0m\n",
      "\u001b[2;36mto \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m. This local configuration will only take effect when you're running\u001b[0m\n",
      "\u001b[2;36mZenML from the initialized repository root, or from a subdirectory. For more \u001b[0m\n",
      "\u001b[2;36minformation on profile and stack configuration, please visit \u001b[0m\n",
      "\u001b[2;4;94mhttps://docs.zenml.io/developer-guide/stacks-profiles-repositories.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize a ZenML repository\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has created a local directory with a bunch of configuration for your MLOPS stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with the local stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "The above commands have automatically created a local MLOps stack for you and set it to active. Let's make sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\r\n",
      "\u001b[?25l\u001b[2;36mThe active stack is: \u001b[0m\u001b[2;32m'default'\u001b[0m\r\n",
      "\u001b[2;32m⠋\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;36mGetting the active stack...\u001b[0m\r",
      "\u001b[2K\u001b[32m⠋\u001b[0m Getting the active stack...\r\n",
      "\u001b[?25h\r",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!zenml stack get\n",
    "#!zenml stack set local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![localstack.png](assets/localstack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default stack is the local stack.\n",
    "Orchestrator: Python Kernel\n",
    "Artifact Store: Stores all the artifacts that flow between steps.\n",
    "Metadata Store: Keeps track of all the artifacts as well as all the parameters that flow through your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Create your first pipeline with the local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "Let's first do the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LvFo9epOUE7G"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from zenml.integrations.constants import TENSORFLOW\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import BaseStepConfig, Output, StepContext, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHcI2FinX2O"
   },
   "source": [
    "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is an `importer` step that downloads a sample of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1VT_PAW10jbp"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray,\n",
    "    X_test=np.ndarray,\n",
    "    y_train=np.ndarray,\n",
    "    y_test=np.ndarray,\n",
    "):\n",
    "    \"\"\"Download the MNIST data store it as an artifact\"\"\"\n",
    "    (X_train, y_train), (\n",
    "        X_test,\n",
    "        y_test,\n",
    "    ) = tf.keras.datasets.mnist.load_data()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "Then we add a `normalizer` step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def normalizer(\n",
    "    X_train: np.ndarray, X_test: np.ndarray\n",
    ") -> Output(X_train_normed=np.ndarray, X_test_normed=np.ndarray):\n",
    "    \"\"\"Normalize digits dataset with mean and standard deviation.\"\"\"\n",
    "    X_train_normed = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "    X_test_normed = (X_test - np.mean(X_test)) / np.std(X_test)\n",
    "    return X_train_normed, X_test_normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma53mucU0yF3"
   },
   "source": [
    "We then add a `trainer` step, that takes the normalized data and trains a Keras model on the data. The step has an associated `TrainerConfig` step configuration class. Also note how we use the `StepContext` to extract the Artifact Store path alongside the output model Artifact where TensorBoard logs are to be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZEw7Cbqx0wXj"
   },
   "outputs": [],
   "source": [
    "class TrainerConfig(BaseStepConfig):\n",
    "    \"\"\"Trainer params\"\"\"\n",
    "\n",
    "    epochs: int = 1\n",
    "    lr: float = 0.001\n",
    "\n",
    "@step\n",
    "def trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    context: StepContext,\n",
    "    config: TrainerConfig,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Train a neural net from scratch to recognize MNIST digits return our\n",
    "    model or the learner\"\"\"\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    log_dir = os.path.join(context.get_output_artifact_uri(), \"logs\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=1\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(config.lr),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=config.epochs,\n",
    "        callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we had an `evaluator` to see how we did on the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: tf.keras.Model,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "\n",
    "    _, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    logging.info(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def mnist_pipeline(\n",
    "    importer,\n",
    "    normalizer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    # Link all the steps together\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    X_trained_normed, X_test_normed = normalizer(X_train=X_train, X_test=X_test)\n",
    "    model = trainer(X_train=X_trained_normed, y_train=y_train)\n",
    "    evaluator(X_test=X_test_normed, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Running the pipeline is as simple as calling the `run()` method on an instance of the defined pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "f61e4408-4001-4cc7-ed7d-8472b1c4089f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mCreating run for pipeline: \u001b[0m\u001b[33mmnist_pipeline\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mCache enabled for pipeline \u001b[0m\u001b[33mmnist_pipeline\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack \u001b[0m\u001b[33mdefault\u001b[1;35m to run pipeline \u001b[0m\u001b[33mmnist_pipeline\u001b[1;35m...\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mimporter\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[33mimporter\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mimporter\u001b[1;35m has finished in 0.072s.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mnormalizer\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[33mnormalizer\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mnormalizer\u001b[1;35m has finished in 0.138s.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mtrainer\u001b[1;35m has started.\u001b[0m\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4884 - accuracy: 0.8523\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mtrainer\u001b[1;35m has finished in 10.658s.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mevaluator\u001b[1;35m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <finalize object at 0x7f06bb5ede80; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/laiml/.pyenv/versions/3.7.6/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/home/laiml/.pyenv/versions/3.7.6/lib/python3.7/tempfile.py\", line 797, in _cleanup\n",
      "    _shutil.rmtree(name)\n",
      "  File \"/home/laiml/.pyenv/versions/3.7.6/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/home/laiml/.pyenv/versions/3.7.6/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpbr3dm_bx'\n",
      "Exception ignored in: <finalize object at 0x7f06bb5ede00; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/laiml/.pyenv/versions/3.7.6/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/home/laiml/.pyenv/versions/3.7.6/lib/python3.7/tempfile.py\", line 797, in _cleanup\n",
      "    _shutil.rmtree(name)\n",
      "  File \"/home/laiml/.pyenv/versions/3.7.6/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/home/laiml/.pyenv/versions/3.7.6/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp3udrshfz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.3035 - accuracy: 0.9142 - 923ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test accuracy: 0.9142000079154968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mStep \u001b[0m\u001b[33mevaluator\u001b[1;35m has finished in 1.417s.\u001b[0m\n",
      "\u001b[1;35mPipeline run \u001b[0m\u001b[33mmnist_pipeline-05_Sep_22-10_57_51_731767\u001b[1;35m has finished in 12.717s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "first_pipeline = mnist_pipeline(\n",
    "    importer=importer(),\n",
    "    normalizer=normalizer(),\n",
    "    trainer=trainer(),\n",
    "    evaluator=evaluator(),\n",
    ")\n",
    "\n",
    "first_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Visualize the model with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "To visualize the model with TensorBoard, make use of the built-in ZenML TensorBoard visualizer, that will automatically start a TensorBoard server in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "f61e4408-4001-4cc7-ed7d-8472b1c4089f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_15425/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2872063960.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_15425/2872063960.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'zenml.integrations.tensorflow.visualizers'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_15425/\u001b[0m\u001b[1;33m2872063960.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_15425/2872063960.py'\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'zenml.integrations.tensorflow.visualizers'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from zenml.integrations.tensorflow.visualizers import (\n",
    "    visualize_tensorboard,\n",
    "    stop_tensorboard_server,\n",
    ")\n",
    "\n",
    "visualize_tensorboard(\n",
    "    pipeline_name=\"mnist_pipeline\",\n",
    "    step_name=\"trainer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stop the TensorBoard server, you can use the `stop_tensorboard` utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_15425/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3920748117.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_15425/3920748117.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'stop_tensorboard_server'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_15425/\u001b[0m\u001b[1;33m3920748117.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_15425/3920748117.py'\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'stop_tensorboard_server'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_tensorboard_server(\n",
    "    pipeline_name=\"mnist_pipeline\",\n",
    "    step_name=\"trainer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gotkJdTQz8j2"
   },
   "source": [
    "# Transitioning to Kubeflow Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMLU4cNW-Ei4"
   },
   "source": [
    "We got pretty good results on the digits model that we trained, but at some point we want to get out of this notebook local stack and go to a stack which looks more like production. Here is where the ZenML [Kubeflow Pipelines](https://github.com/kubeflow/pipelines) integration helps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this example, you need to have installed:\n",
    "\n",
    "* [Docker](https://docs.docker.com/get-docker/)\n",
    "* [K3D](https://k3d.io/v5.2.1/) \n",
    "* [Kubectl](https://kubernetes.io/docs/tasks/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Kubeflow Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![localstack-with-kubeflow.png](assets/localstack-with-kubeflow-orchestrator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZenML version: 0.13.1\r\n",
      "Install path: /home/laiml/.pyenv/versions/3.7.6/lib/python3.7/site-packages/zenml\r\n",
      "Python version: 3.7.6\r\n",
      "Platform information: {'os': 'linux', 'linux_distro': 'ubuntu', 'linux_distro_like': 'debian', 'linux_distro_version': '18.04'}\r\n",
      "Environment: native\r\n",
      "Integrations: ['kubeflow', 'kubernetes', 'tensorboard', 'tensorflow']\r\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import zenml.environment; print(zenml.environment.get_system_details())\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the container-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠏\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠋\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Registering container registry 'local_register'...\n",
      "\u001b[1;35mRegistered stack component with type 'container_registry' and name 'local_register'.\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering container registry 'local_register'...\n",
      "\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mSuccessfully registered container registry `local_register`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml container-registry register local_register --flavor=default --uri=localhost:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠇\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠋\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\u001b[1;35mRegistered stack component with type 'orchestrator' and name 'kubeflow_orchestrator'.\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Registering orchestrator 'kubeflow_orchestrator'...\n",
      "\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mSuccessfully registered orchestrator `kubeflow_orchestrator`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml orchestrator register kubeflow_orchestrator --flavor=kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the local registry and orchestrator and register it in a local_kubeflow_stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠏\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠋\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\u001b[1;35mRegistered stack with name 'local_kubeflow_stack'.\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mStack \u001b[0m\u001b[2;32m'local_kubeflow_stack'\u001b[0m\u001b[2;36m successfully registered!\u001b[0m\n",
      "\u001b[2;32m⠧\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;36mRegistering stack 'local_kubeflow_stack'...\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Registering stack 'local_kubeflow_stack'...\n",
      "\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!zenml stack register local_kubeflow_stack -m default -a default -o kubeflow_orchestrator -c local_register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the local_kubeflow_stack as active:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[2K\u001b[2;36mActive stack set to: \u001b[0m\u001b[2;32m'local_kubeflow_stack'\u001b[0m.\n",
      "\u001b[2K\u001b[32m⠼\u001b[0m Setting the active stack to 'local_kubeflow_stack'...beflow_stack'...\u001b[0m\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!zenml stack set local_kubeflow_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets spin the stack up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\r\n",
      "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:44:59Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n",
      "Kustomize Version: v4.5.7\r\n",
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k3d version v5.4.6\r\n",
      "k3s version v1.24.4-k3s1 (default)\r\n"
     ]
    }
   ],
   "source": [
    "!k3d version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[2;36mProvisioning resources for active stack \u001b[0m\u001b[2;32m'local_kubeflow_stack'\u001b[0m\u001b[2;36m.\u001b[0m\n",
      "\u001b[1;35mProvisioning resources for stack 'local_kubeflow_stack'.\u001b[0m\n",
      "\u001b[1;35mProvisioning local Kubeflow Pipelines deployment...\u001b[0m\n",
      "\u001b[1;35mCreating local K3D cluster 'zenml-kubeflow-82e3ca95'.\u001b[0m\n",
      "\u001b[33mWARN\u001b[0m[0000] No node filter specified                     \n",
      "\u001b[36mINFO\u001b[0m[0000] Prep: Network                                \n",
      "\u001b[36mINFO\u001b[0m[0000] Created network 'k3d-zenml-kubeflow-82e3ca95' \n",
      "\u001b[36mINFO\u001b[0m[0000] Created image volume k3d-zenml-kubeflow-82e3ca95-images \n",
      "\u001b[36mINFO\u001b[0m[0000] Creating node 'k3d-zenml-kubeflow-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0004] Pulling image 'docker.io/library/registry:2' \n",
      "\u001b[36mINFO\u001b[0m[0012] Successfully created registry 'k3d-zenml-kubeflow-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0012] Starting new tools node...                   \n",
      "\u001b[36mINFO\u001b[0m[0013] Creating node 'k3d-zenml-kubeflow-82e3ca95-server-0' \n",
      "\u001b[36mINFO\u001b[0m[0014] Pulling image 'ghcr.io/k3d-io/k3d-tools:5.4.6' \n",
      "\u001b[36mINFO\u001b[0m[0018] Pulling image 'rancher/k3s:v1.23.5-k3s1'     \n",
      "\u001b[36mINFO\u001b[0m[0019] Starting Node 'k3d-zenml-kubeflow-82e3ca95-tools' \n",
      "\u001b[36mINFO\u001b[0m[0052] Creating LoadBalancer 'k3d-zenml-kubeflow-82e3ca95-serverlb' \n",
      "\u001b[36mINFO\u001b[0m[0053] Pulling image 'ghcr.io/k3d-io/k3d-proxy:5.4.6' \n",
      "\u001b[36mINFO\u001b[0m[0063] Using the k3d-tools node to gather environment information \n",
      "\u001b[36mINFO\u001b[0m[0063] HostIP: using network gateway 172.18.0.1 address \n",
      "\u001b[36mINFO\u001b[0m[0063] Starting cluster 'zenml-kubeflow-82e3ca95'   \n",
      "\u001b[36mINFO\u001b[0m[0063] Starting servers...                          \n",
      "\u001b[36mINFO\u001b[0m[0063] Starting Node 'k3d-zenml-kubeflow-82e3ca95-server-0' \n",
      "\u001b[36mINFO\u001b[0m[0068] All agents already running.                  \n",
      "\u001b[36mINFO\u001b[0m[0068] Starting helpers...                          \n",
      "\u001b[36mINFO\u001b[0m[0068] Starting Node 'k3d-zenml-kubeflow-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0068] Starting Node 'k3d-zenml-kubeflow-82e3ca95-serverlb' \n",
      "\u001b[36mINFO\u001b[0m[0075] Injecting records for hostAliases (incl. host.k3d.internal) and for 3 network members into CoreDNS configmap... \n",
      "\u001b[36mINFO\u001b[0m[0079] Cluster 'zenml-kubeflow-82e3ca95' created successfully! \n",
      "\u001b[36mINFO\u001b[0m[0079] You can now use it like this:                \n",
      "kubectl cluster-info\n",
      "\u001b[1;35mFinished K3D cluster creation.\u001b[0m\n",
      "\u001b[1;35mDeploying Kubeflow Pipelines.\u001b[0m\n",
      "error: git cmd = '/usr/bin/git fetch --depth=1 origin 1.8.1': exit status 128\n",
      "\u001b[31mCommand '['kubectl', '--context', 'k3d-zenml-kubeflow-82e3ca95', 'apply', '-k', 'github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=1.8.1&timeout=5m']' returned non-zero exit status 1.\u001b[0m\n",
      "\u001b[31mUnable to spin up local Kubeflow Pipelines deployment.\u001b[0m\n",
      "\u001b[1;35mIf you wish to spin up this Kubeflow local orchestrator manually, please enter the following commands:\n",
      "\u001b[0m\n",
      "\u001b[1;35m> k3d cluster create zenml-kubeflow-82e3ca95 --image rancher/k3s:v1.23.5-k3s1 --registry-create k3d-zenml-kubeflow-registry.localhost:5000 --registry-config /home/laiml/.config/zenml/kubeflow/82e3ca95-50b5-405e-9229-351c82b4dcc7/k3d_registry.yaml --volume /home/laiml/.config/zenml:/home/laiml/.config/zenml\n",
      "\n",
      "> kubectl --context k3d-zenml-kubeflow-82e3ca95 apply -k github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=1.8.1&timeout=5m\n",
      "> kubectl --context k3d-zenml-kubeflow-82e3ca95 wait --timeout=60s --for condition=established crd/applications.app.k8s.io\n",
      "> kubectl --context k3d-zenml-kubeflow-82e3ca95 apply -k github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic-pns?ref=1.8.1&timeout=5m\n",
      "> kubectl --context k3d-zenml-kubeflow-82e3ca95 --namespace kubeflow port-forward svc/ml-pipeline-ui 8080:80\u001b[0m\n",
      "\u001b[36mINFO\u001b[0m[0000] Deleting cluster 'zenml-kubeflow-82e3ca95'   \n",
      "\u001b[36mINFO\u001b[0m[0001] Deleting cluster network 'k3d-zenml-kubeflow-82e3ca95' \n",
      "\u001b[36mINFO\u001b[0m[0001] Deleting 2 attached volumes...               \n",
      "\u001b[33mWARN\u001b[0m[0001] Failed to delete volume 'k3d-zenml-kubeflow-82e3ca95-images' of cluster 'zenml-kubeflow-82e3ca95': failed to find volume 'k3d-zenml-kubeflow-82e3ca95-images': Error: No such volume: k3d-zenml-kubeflow-82e3ca95-images -> Try to delete it manually \n",
      "\u001b[36mINFO\u001b[0m[0001] Removing cluster details from default kubeconfig... \n",
      "\u001b[36mINFO\u001b[0m[0001] Removing standalone kubeconfig file (if there is one)... \n",
      "\u001b[36mINFO\u001b[0m[0001] Successfully deleted cluster zenml-kubeflow-82e3ca95! \n",
      "\u001b[1;35mDeleted local k3d cluster 'zenml-kubeflow-82e3ca95'.\u001b[0m\n",
      "\u001b[1;35mLocal kubeflow pipelines deployment deprovisioned.\u001b[0m\n",
      "\u001b[1;35mProvisioned resources for KubeflowOrchestrator(type=orchestrator, flavor=kubeflow, docker_parent_image=None, name=kubeflow_orchestrator, uuid=82e3ca95-50b5-405e-9229-351c82b4dcc7, custom_docker_base_image_name=None, kubeflow_pipelines_ui_port=8080, kubeflow_hostname=None, kubernetes_context=k3d-zenml-kubeflow-82e3ca95, synchronous=False, skip_local_validations=False, skip_cluster_provisioning=False, skip_ui_daemon_provisioning=False).\u001b[0m\n",
      "\u001b[1;35mResuming provisioned resources for stack local_kubeflow_stack.\u001b[0m\n",
      "Error: \u001b[31m\u001b[1mUnable to resume resources for KubeflowOrchestrator(type=orchestrator, flavor=kubeflow, docker_parent_image=None, name=kubeflow_orchestrator, uuid=82e3ca95-50b5-405e-9229-351c82b4dcc7, custom_docker_base_image_name=None, kubeflow_pipelines_ui_port=8080, kubeflow_hostname=None, kubernetes_context=k3d-zenml-kubeflow-82e3ca95, synchronous=False, skip_local_validations=False, skip_cluster_provisioning=False, skip_ui_daemon_provisioning=False): No resources have been provisioned for this component.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml stack up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the pipeline to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run-kubeflow.py\n",
    "#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at:\n",
    "#\n",
    "#       https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n",
    "#  or implied. See the License for the specific language governing\n",
    "#  permissions and limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from zenml.integrations.constants import TENSORFLOW\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.repository import Repository\n",
    "from zenml.steps import BaseStepConfig, Output, StepContext, step\n",
    "\n",
    "\n",
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray,\n",
    "    X_test=np.ndarray,\n",
    "    y_train=np.ndarray,\n",
    "    y_test=np.ndarray,\n",
    "):\n",
    "    \"\"\"Download the MNIST data store it as an artifact\"\"\"\n",
    "    (X_train, y_train), (\n",
    "        X_test,\n",
    "        y_test,\n",
    "    ) = tf.keras.datasets.mnist.load_data()\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "@step\n",
    "def normalizer(\n",
    "    X_train: np.ndarray, X_test: np.ndarray\n",
    ") -> Output(X_train_normed=np.ndarray, X_test_normed=np.ndarray):\n",
    "    \"\"\"Normalize digits dataset with mean and standard deviation.\"\"\"\n",
    "    X_train_normed = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "    X_test_normed = (X_test - np.mean(X_test)) / np.std(X_test)\n",
    "    return X_train_normed, X_test_normed\n",
    "\n",
    "\n",
    "class TrainerConfig(BaseStepConfig):\n",
    "    \"\"\"Trainer params\"\"\"\n",
    "\n",
    "    epochs: int = 1\n",
    "    lr: float = 0.001\n",
    "\n",
    "\n",
    "@step\n",
    "def trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    context: StepContext,\n",
    "    config: TrainerConfig,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Train a neural net from scratch to recognize MNIST digits return our\n",
    "    model or the learner\"\"\"\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    log_dir = os.path.join(context.get_output_artifact_uri(), \"logs\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=1\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(config.lr),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=config.epochs,\n",
    "        callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: tf.keras.Model,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "\n",
    "    _, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    logging.info(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "@pipeline(required_integrations=[TENSORFLOW], enable_cache=False)\n",
    "def mnist_pipeline(\n",
    "    importer,\n",
    "    normalizer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    # Link all the steps together\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    X_trained_normed, X_test_normed = normalizer(X_train=X_train, X_test=X_test)\n",
    "    model = trainer(X_train=X_trained_normed, y_train=y_train)\n",
    "    evaluator(X_test=X_test_normed, y_test=y_test, model=model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the pipeline\n",
    "    pipeline_instance = mnist_pipeline(\n",
    "        importer=importer(),\n",
    "        normalizer=normalizer(),\n",
    "        trainer=trainer(),\n",
    "        evaluator=evaluator(),\n",
    "    )\n",
    "    pipeline_instance.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new pipeline\n",
    "!python run-kubeflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uKNmljpIYRh"
   },
   "source": [
    "# Post execution workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5yPNQ1fIYRh"
   },
   "outputs": [],
   "source": [
    "from zenml.repository import Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhG-rEDZIYRi"
   },
   "source": [
    "## Get repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cZqhydiIYRj"
   },
   "outputs": [],
   "source": [
    "repo = Repository()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-rao3-oIYRj"
   },
   "source": [
    "## Pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxMk-vsmIYRk"
   },
   "outputs": [],
   "source": [
    "pipelines = repo.get_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFd--JgZIYRk"
   },
   "source": [
    "## Retrieve the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BSbKed-IYRk"
   },
   "outputs": [],
   "source": [
    "mnist_pipeline = pipelines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpNKuyChIYRl"
   },
   "source": [
    "## Get the first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI57bWbHIYRl"
   },
   "outputs": [],
   "source": [
    "runs = mnist_pipeline.runs  # chronologically ordered\n",
    "mnist_run = runs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIPmpQCrIYRl"
   },
   "source": [
    "## Get the second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SGaTPduIYRl"
   },
   "outputs": [],
   "source": [
    "kubeflow_mnist_run = runs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDR1JNHtIYRm"
   },
   "source": [
    "## Get the steps (note the first step name is different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vct_wqq1IYRm",
    "outputId": "7800431d-813b-4721-f61d-27f4012f9d2d"
   },
   "outputs": [],
   "source": [
    "mnist_run.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnQkTAv6IYRm",
    "outputId": "8fedfaf1-b5c9-4218-809c-244b8f6ebc2c"
   },
   "outputs": [],
   "source": [
    "kubeflow_mnist_run.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m6d6VPDIYRn"
   },
   "source": [
    "## Check the results of the evaluator and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sF7YM4_iIYRn"
   },
   "outputs": [],
   "source": [
    "mnist_eval_step = mnist_run.get_step(step='evaluator')\n",
    "kubeflow_mnist_eval_step = kubeflow_mnist_run.get_step(step='evaluator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5fvkLoZIYRn",
    "outputId": "a8d0ad4d-bbd0-4320-a282-870120ac3ddf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One output is simply called `output`, multiple is a dict called `outputs`.\n",
    "mnist_eval_step.output.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMBKfBSeIYRo",
    "outputId": "4387f938-bb21-492e-9c90-79a8b4329101"
   },
   "outputs": [],
   "source": [
    "kubeflow_mnist_eval_step.output.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Tan15BgIYRo"
   },
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "… and that's it!. If you came here without a hiccup, you must have successly installed ZenML, set up a ZenML repo, configured a training pipeline, executed it and evaluated the results. You have also deployed said pipeline to a production MLOps stack from right within your notebook! Hurray!\n",
    "\n",
    "However, if you had a hiccup or you have some suggestions/questions regarding our framework, you can always check our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) or even better join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22gkBKSntlF8"
   },
   "source": [
    "For more detailed information on all the components and steps that went into this short example, please continue reading [our more detailed documentation pages](https://docs.zenml.io/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
